import { useState, useEffect, useRef } from 'react';
import { Meditation } from '@shared/schema';
import { cn } from '@/lib/utils';

interface AudioPlayerProps {
  meditation: Meditation | null;
  isPlaying: boolean;
  setIsPlaying: (playing: boolean) => void;
}

export default function AudioPlayer({ meditation, isPlaying, setIsPlaying }: AudioPlayerProps) {
  const [progress, setProgress] = useState(0);
  const [currentTime, setCurrentTime] = useState(0);
  const [duration, setDuration] = useState(0);
  
  const speechSynthRef = useRef<SpeechSynthesisUtterance | null>(null);
  const progressTimerRef = useRef<number | null>(null);
  const startTimeRef = useRef<number>(0);
  
  // Format time in MM:SS
  const formatTime = (timeInSeconds: number) => {
    const minutes = Math.floor(timeInSeconds / 60);
    const seconds = Math.floor(timeInSeconds % 60);
    return `${minutes}:${seconds < 10 ? '0' : ''}${seconds}`;
  };
  
  // Initialize when meditation changes
  useEffect(() => {
    if (!meditation) return;
    
    // Stop existing speech synthesis if it's active
    if (speechSynthRef.current) {
      window.speechSynthesis.cancel();
      speechSynthRef.current = null;
    }
    
    // Reset state
    setProgress(0);
    setCurrentTime(0);
    
    // Calculate estimated duration (roughly 0.5 seconds per word for meditation)
    const wordCount = meditation.meditationScript?.split(/\s+/).length || 0;
    const estimatedDuration = Math.max(meditation.duration * 60, wordCount * 0.5);
    setDuration(estimatedDuration);
    
    // Clean up on unmount
    return () => {
      if (speechSynthRef.current) {
        window.speechSynthesis.cancel();
        speechSynthRef.current = null;
      }
      
      if (progressTimerRef.current) {
        window.clearInterval(progressTimerRef.current);
        progressTimerRef.current = null;
      }
    };
  }, [meditation]);
  
  // Handle play/pause state
  useEffect(() => {
    if (!meditation || !meditation.meditationScript) return;
    
    if (isPlaying) {
      // Use Web Speech API for reliable audio playback
      if (window.speechSynthesis) {
        // If we're already speaking, don't restart
        if (window.speechSynthesis.speaking && speechSynthRef.current) {
          window.speechSynthesis.resume();
          return;
        }
        
        // Otherwise start new utterance
        const utterance = new SpeechSynthesisUtterance(meditation.meditationScript);
        
        // Initialize voices
        let voices = window.speechSynthesis.getVoices();
        if (voices.length === 0) {
          // If voices aren't loaded yet, wait for them
          window.speechSynthesis.onvoiceschanged = () => {
            voices = window.speechSynthesis.getVoices();
            if (voices.length > 0) {
              setVoiceAndSpeak();
            }
          };
        } else {
          setVoiceAndSpeak();
        }
        
        function setVoiceAndSpeak() {
          // Choose appropriate voice based on voice style
          let voiceSearch = 'Female';
          if (meditation.voiceStyle) {
            if (meditation.voiceStyle.includes('male')) {
              voiceSearch = 'Male';
            }
            
            // Adjust speech parameters based on style
            if (meditation.voiceStyle.includes('whisper')) {
              utterance.volume = 0.7;
              utterance.rate = 0.8;
              utterance.pitch = 0.8;
            } else if (meditation.voiceStyle.includes('motivational')) {
              utterance.volume = 1.0;
              utterance.rate = 1.0; 
              utterance.pitch = 1.1;
            } else {
              // Calm voice (default)
              utterance.volume = 0.9;
              utterance.rate = 0.9;
              utterance.pitch = 1.0;
            }
          }
          
          // Try to find appropriate voice
          const voices = window.speechSynthesis.getVoices();
          const voiceIndex = voices.findIndex(voice => voice.name.includes(voiceSearch));
          if (voiceIndex !== -1) {
            utterance.voice = voices[voiceIndex];
          }
          
          // Set up events
          utterance.onend = () => {
            setIsPlaying(false);
            speechSynthRef.current = null;
            
            // Reset progress
            setProgress(0);
            setCurrentTime(0);
            
            // Clear timer
            if (progressTimerRef.current) {
              window.clearInterval(progressTimerRef.current);
              progressTimerRef.current = null;
            }
          };
          
          // Start speech
          speechSynthRef.current = utterance;
          startTimeRef.current = Date.now();
          window.speechSynthesis.speak(utterance);
        }
        
        // Start progress timer to simulate progress bar
        if (progressTimerRef.current) {
          window.clearInterval(progressTimerRef.current);
        }
        
        startTimeRef.current = Date.now();
        progressTimerRef.current = window.setInterval(() => {
          const elapsed = (Date.now() - startTimeRef.current) / 1000;
          setCurrentTime(elapsed);
          
          // Calculate progress as percentage
          const percent = Math.min(100, (elapsed / duration) * 100);
          setProgress(percent);
          
          // Stop timer if we reach 100%
          if (percent >= 100) {
            if (progressTimerRef.current) {
              window.clearInterval(progressTimerRef.current);
              progressTimerRef.current = null;
            }
          }
        }, 100);
      }
    } else {
      // Pause speech synthesis
      if (window.speechSynthesis && window.speechSynthesis.speaking) {
        window.speechSynthesis.pause();
      }
      
      // Pause progress timer
      if (progressTimerRef.current) {
        window.clearInterval(progressTimerRef.current);
        progressTimerRef.current = null;
      }
    }
    
    // Clean up on unmount
    return () => {
      if (progressTimerRef.current) {
        window.clearInterval(progressTimerRef.current);
        progressTimerRef.current = null;
      }
      
      if (speechSynthRef.current) {
        window.speechSynthesis.cancel();
        speechSynthRef.current = null;
      }
    };
  }, [isPlaying, meditation, duration, setIsPlaying]);
  
  // Toggle play/pause
  const togglePlayPause = () => {
    setIsPlaying(!isPlaying);
  };

  // If no meditation, show nothing
  if (!meditation) {
    return null;
  }

  return (
    <div className="bg-white rounded-lg shadow-md p-6">
      <div className="flex flex-col items-center space-y-4">
        <h3 className="text-xl font-semibold text-center mb-3">{meditation.title}</h3>
        
        {/* Waveform Visualization */}
        <div className="w-full h-24 bg-gray-100 rounded-lg flex items-center justify-center overflow-hidden relative">
          <div className="w-full h-full flex items-center justify-center">
            <div className={cn(
              "flex items-end space-x-1 h-full w-4/5 px-4 transition-all",
              isPlaying ? "opacity-100" : "opacity-50"
            )}>
              {/* Audio visualization bars that animate when playing */}
              {Array.from({ length: 30 }).map((_, i) => {
                const height = isPlaying 
                  ? 20 + Math.sin(i * 0.5 + currentTime * 2) * 10 + Math.random() * 10
                  : 15 + Math.sin(i * 0.2) * 5;
                
                return (
                  <div 
                    key={i}
                    style={{ 
                      height: `${height}px`,
                      transition: 'height 0.1s ease'
                    }}
                    className="w-2 bg-gradient-to-t from-accent to-primary rounded-full"
                  />
                );
              })}
            </div>
          </div>
          
          {/* Overlay for play button when paused */}
          {!isPlaying && (
            <div className="absolute inset-0 flex items-center justify-center bg-black bg-opacity-10 rounded-lg">
              <button 
                className="w-14 h-14 rounded-full bg-white shadow-md flex items-center justify-center"
                onClick={togglePlayPause} 
                aria-label="Play"
              >
                <svg xmlns="http://www.w3.org/2000/svg" className="h-6 w-6 text-accent" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z" />
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
                </svg>
              </button>
            </div>
          )}
        </div>
        
        {/* Playback Controls */}
        <div className="w-full flex items-center space-x-2">
          <span className="text-sm text-gray-600 w-10 text-right">{formatTime(currentTime)}</span>
          <input 
            type="range" 
            min="0" 
            max="100" 
            value={progress} 
            onChange={(e) => {
              // For now, we don't support seeking in Web Speech API
              // This is just for UI display
              setProgress(parseFloat(e.target.value));
            }}
            className="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer accent-primary"
          />
          <span className="text-sm text-gray-600 w-10">{formatTime(duration)}</span>
        </div>
        
        {/* Play/Pause Button */}
        <div className="flex items-center justify-between w-full">
          <button 
            className={`w-12 h-12 rounded-full flex items-center justify-center ${isPlaying ? 'bg-purple-500 text-white' : 'bg-white text-purple-500 border border-purple-500'}`}
            onClick={togglePlayPause}
            aria-label={isPlaying ? 'Pause' : 'Play'}
          >
            {isPlaying ? (
              <svg xmlns="http://www.w3.org/2000/svg" className="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z" />
              </svg>
            ) : (
              <svg xmlns="http://www.w3.org/2000/svg" className="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z" />
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
              </svg>
            )}
          </button>
          
          <div className="flex items-center">
            <div className="text-sm text-gray-700">
              <div className="font-medium">{meditation.voiceStyle || 'Calm Voice'}</div>
              <div className="text-xs text-gray-500">
                {meditation.backgroundMusic && meditation.backgroundMusic !== 'none' ? (
                  <span>{meditation.backgroundMusic} • </span>
                ) : null}
                {meditation.duration} min
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}